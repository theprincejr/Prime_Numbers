{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theprincejr/Prime_Numbers/blob/master/Telegram_Downloader_Script_(Remux_to_Temp_Folder_and_Replace).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "from pyrogram import Client, filters, enums # Import enums for parse mode\n",
        "from tqdm import tqdm # Keep tqdm for potential future use or if needed elsewhere\n",
        "import os\n",
        "# Removed import time # Removed unused import time\n",
        "import subprocess\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "import logging\n",
        "import sys # Import sys for exiting on critical errors\n",
        "# Removed import psutil # Removed psutil as system stats are removed\n",
        "# Removed import hashlib # Removed hashlib as hash checking is removed\n",
        "import requests # Added to trigger Emby scan via API (though now handled by scanner)\n",
        "from contextlib import nullcontext # Keep nullcontext for potential future use\n",
        "import shutil # Added for moving files\n",
        "import re # Import re for sanitizing filenames\n",
        "import time # Re-imported time for duration calculation\n",
        "\n",
        "# === Load Environment Variables ===\n",
        "load_dotenv() # Load environment variables from .env file\n",
        "\n",
        "# === Configuration from Environment Variables (pre-logging setup) ===\n",
        "# Use os.getenv() to read values from environment variables.\n",
        "# Provide default values where appropriate, or raise errors for required variables.\n",
        "\n",
        "# Telegram Setup (Read first for logging setup)\n",
        "# API_ID and API_HASH are required. Exit if not found.\n",
        "api_id_str = os.getenv('API_ID')\n",
        "api_hash = os.getenv('API_HASH') # Corrected case to match common convention\n",
        "\n",
        "# Session file path (defaults to a relative path within the project directory)\n",
        "SESSION_FILE_PATH = os.getenv('SESSION_FILE', 'my_account.session') # Updated default path\n",
        "\n",
        "# Download Paths (defaults if not set - these should remain on the SSD)\n",
        "DOWNLOAD_FOLDER = os.getenv('DOWNLOAD_DIR', '/mnt/ssd/telegram_downloads')\n",
        "OTHER_FOLDER = os.path.join(DOWNLOAD_FOLDER, \"others\")\n",
        "\n",
        "# Temporary directory for remuxing (MUST be outside DOWNLOAD_FOLDER)\n",
        "REMUX_TEMP_DIR = os.getenv('REMUX_TEMP_DIR', '/mnt/ssd/telegram_remux_temp') # New environment variable\n",
        "\n",
        "# Log File Path (defaults to a relative path within the project directory)\n",
        "LOG_FILE = os.getenv('LOG_FILE', 'telegram_downloader.log') # Updated default path\n",
        "\n",
        "# Chat ID for filtering messages (defaults to 'me' if not set)\n",
        "# Pyrogram's filters.chat() can take string usernames ('me', '@username') or integer IDs.\n",
        "chat_filter_id_env = os.getenv('CHAT_ID', 'me')\n",
        "\n",
        "# Convert chat_filter_id to integer if it looks like one, otherwise keep as string\n",
        "try:\n",
        "    # Attempt to convert to int, but handle empty string or non-numeric\n",
        "    if chat_filter_id_env is not None and str(chat_filter_id_env).strip().isdigit():\n",
        "        chat_filter_id = int(str(chat_filter_id_env).strip())\n",
        "    else:\n",
        "        chat_filter_id = chat_filter_id_env # Keep as string if not an integer or is None/empty\n",
        "except ValueError:\n",
        "    # This block should ideally not be reached due to the isdigit() check, but as a safeguard\n",
        "    chat_filter_id = chat_filter_id_env # Keep as string on unexpected ValueError\n",
        "\n",
        "\n",
        "# Path to the downloader status file (defaults to a relative path within the project directory)\n",
        "DOWNLOADER_STATUS_FILE = os.getenv('DOWNLOADER_STATUS_FILE', '/home/pi/project_d/telegram_downloader/downloader_status.txt') # Updated default path\n",
        "\n",
        "# Removed NOTIFICATION_CHAT_ID as notifications are not sent from here\n",
        "\n",
        "# Emby Server Details (Required for triggering scan - now handled by scanner script)\n",
        "# Keeping these variables for the trigger_emby_scan_from_downloader function if needed elsewhere\n",
        "EMBY_URL = os.getenv('EMBY_URL')\n",
        "EMBY_API_KEY = os.getenv('EMBY_API_KEY')\n",
        "\n",
        "\n",
        "# === Logging Setup ===\n",
        "# Configure logging AFTER reading LOG_FILE from environment, but BEFORE critical checks\n",
        "# Ensure the log directory exists (will be the current working directory if path is relative)\n",
        "log_dir = os.path.dirname(LOG_FILE)\n",
        "if log_dir and log_dir != '' and not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, # Keep INFO level for general operation\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    handlers=[\n",
        "        logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8'),\n",
        "        logging.StreamHandler(sys.stdout) # Use sys.stdout for stream handler\n",
        "    ]\n",
        ")\n",
        "logging.info(\"Logging configured.\") # Add a log message to confirm logging is active\n",
        "\n",
        "# === Configuration Validation (post-logging setup) ===\n",
        "# Now perform checks and exit if necessary, ensuring errors are logged to file\n",
        "\n",
        "if not api_id_str:\n",
        "    logging.error(\"FATAL: API_ID environment variable not set.\")\n",
        "    sys.exit(1)\n",
        "if not api_hash:\n",
        "    logging.error(\"FATAL: API_hash environment variable not set.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    api_id = int(api_id_str)\n",
        "except ValueError:\n",
        "    logging.error(f\"FATAL: API_ID environment variable '{api_id_str}' is not a valid integer.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Ensure download folders exist AFTER reading DOWNLOAD_FOLDER from environment\n",
        "# Also ensure the parent directory of the session file exists if it's not home\n",
        "# Note: If SESSION_FILE_PATH is a relative path like 'my_account.session',\n",
        "# os.path.dirname() will return '', and os.makedirs('') does nothing, which is correct.\n",
        "session_dir = os.path.dirname(SESSION_FILE_PATH)\n",
        "if session_dir and session_dir != '' and not os.path.exists(session_dir):\n",
        "    os.makedirs(session_dir, exist_ok=True)\n",
        "    logging.info(f\"Created session file directory: {session_dir}\")\n",
        "\n",
        "\n",
        "os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(OTHER_FOLDER, exist_ok=True)\n",
        "# Ensure the temporary remux directory exists\n",
        "os.makedirs(REMUX_TEMP_DIR, exist_ok=True)\n",
        "\n",
        "logging.info(f\"Download folder set to: {DOWNLOAD_FOLDER}\")\n",
        "logging.info(f\"Other files folder set to: {OTHER_FOLDER}\")\n",
        "logging.info(f\"Remux temporary folder set to: {REMUX_TEMP_DIR}\") # Log the new directory\n",
        "logging.info(f\"Session file path set to: {SESSION_FILE_PATH}\")\n",
        "logging.info(f\"Chat filter ID set to: {chat_filter_id}\")\n",
        "logging.info(f\"Downloader status file set to: {DOWNLOADER_STATUS_FILE}\")\n",
        "\n",
        "# Validate Emby configuration if needed - now only used for the trigger function if called\n",
        "# This check is still useful to know if the variables are loaded correctly in the downloader's env\n",
        "# Changed logging level from warning to debug for this check\n",
        "if not EMBY_URL or not EMBY_API_KEY:\n",
        "    logging.debug(\"Emby URL or API Key not set in downloader's environment. Manual Emby scan trigger from downloader will be skipped.\")\n",
        "else:\n",
        "    logging.info(f\"Emby URL set in downloader's environment: {EMBY_URL}\")\n",
        "\n",
        "\n",
        "MAX_RETRIES = 3\n",
        "RETRY_TAIL_SIZE = 3 * 1024 * 1024 # Last 3MB for integrity retry\n",
        "\n",
        "# Initialize the Pyrogram client\n",
        "# Use the variables read from the environment\n",
        "app = Client(SESSION_FILE_PATH, api_id=api_id, api_hash=api_hash)\n",
        "logging.debug(f\"[DEBUG] Pyrogram client initialized.\")\n",
        "\n",
        "\n",
        "# Dictionary to store filename and their size immediately after initial download\n",
        "# This is for duplicate checking based on pre-remux size during the current run.\n",
        "# This dictionary is reset each time the script starts.\n",
        "downloaded_file_sizes = {}\n",
        "\n",
        "# Removed Variable to track the current download status\n",
        "# Removed Variable to track the current download filename\n",
        "\n",
        "def is_video(message):\n",
        "    # Check if the message has a document and its mime type starts with video/\n",
        "    # This is a good check.\n",
        "    # Also check if it's a native video object\n",
        "    return (message.document and message.document.mime_type and message.document.mime_type.startswith(\"video/\")) or message.video\n",
        "\n",
        "# Removed the verify_video_ffmpeg function as requested.\n",
        "\n",
        "# Removed calculate_file_hash function\n",
        "# Removed notify_duplicate function\n",
        "\n",
        "# === Emby Scan Trigger Function (called from downloader - now only for manual trigger if needed) ===\n",
        "# This function is no longer called automatically on download start/end in this version\n",
        "# Keeping the function definition in case it's useful for debugging or future manual triggers\n",
        "def trigger_emby_scan_from_downloader():\n",
        "    \"\"\"Sends a request to the Emby API to trigger a library scan.\"\"\"\n",
        "    # This check is important here - it's why the warning appears in the log\n",
        "    # Changed logging level from warning to debug for this check\n",
        "    if not EMBY_URL or not EMBY_API_KEY:\n",
        "        logging.debug(\"Emby URL or API Key not set in downloader's environment. Skipping Emby scan trigger.\")\n",
        "        return\n",
        "\n",
        "    # Emby API endpoint for library refresh, includes api_key in the URL\n",
        "    # Assuming the endpoint is /Library/Refresh based on typical Emby API\n",
        "    scan_endpoint = f\"{EMBY_URL}/Library/Refresh?api_key={EMBY_API_KEY}\"\n",
        "\n",
        "    # Headers might not be strictly necessary for this endpoint with API key in URL,\n",
        "    # but including Content-Type is good practice.\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    logging.info(f\"Attempting to trigger Emby scan via API from downloader: {scan_endpoint.split('?')[0]}...\") # Log URL without API key\n",
        "\n",
        "    try:\n",
        "        # Send a POST request to the refresh endpoint\n",
        "        response = requests.post(scan_endpoint, headers=headers)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "        logging.info(f\"Emby scan triggered successfully from downloader. Response status code: {response.status_code}\")\n",
        "        # Emby API /Library/Refresh typically returns 204 No Content on success.\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logging.error(f\"Downloader failed to trigger Emby scan via API. Error: {e}\")\n",
        "        # Log response details if available for debugging\n",
        "        if hasattr(e, 'response') and e.response is not None:\n",
        "            logging.error(f\"Emby API response status: {e.response.status_code}\")\n",
        "            logging.error(f\"Emby API response body: {e.response.text}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred while triggering Emby scan from downloader: {e}\")\n",
        "\n",
        "\n",
        "# Modified remux_video_ffmpeg to accept input and output paths\n",
        "def remux_video_ffmpeg(input_path, output_path):\n",
        "    \"\"\"Remuxes a video file to MKV format using FFmpeg.\"\"\"\n",
        "    logging.info(f\"[REMUX] Starting remux of '{os.path.basename(input_path)}' to MKV.\")\n",
        "    # Update status file for remuxing (multi-line)\n",
        "    update_status_file(f\"Status: Remuxing {os.path.basename(input_path)}\")\n",
        "\n",
        "    # FFmpeg command to remux (copying streams without re-encoding)\n",
        "    # -i: input file\n",
        "    # -c copy: copy all streams (video, audio, subtitles) without re-encoding\n",
        "    # -map 0: include all streams from the input\n",
        "    # -y: overwrite output file without asking\n",
        "    # output_path: the output MKV file\n",
        "    command = [\n",
        "        'ffmpeg',\n",
        "        '-i', input_path,\n",
        "        '-c', 'copy',\n",
        "        '-map', '0',\n",
        "        '-y',\n",
        "        output_path\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Run the FFmpeg command\n",
        "        process = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        # Keep FFmpeg output at DEBUG level, so it doesn't clutter INFO logs\n",
        "        logging.debug(f\"[REMUX] FFmpeg stdout:\\n{process.stdout}\")\n",
        "        logging.debug(f\"[REMUX] FFmpeg stderr:\\n{process.stderr}\")\n",
        "        logging.info(f\"[REMUX] Successfully remuxed: {os.path.basename(input_path)}\")\n",
        "\n",
        "        # Remove the original file after successful remux - HANDLED AFTER REMUX CALL\n",
        "\n",
        "        return True # Remux successful\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        logging.error(f\"[REMUX] FFmpeg remux failed for '{os.path.basename(input_path)}'. Error: {e}\")\n",
        "        logging.error(f\"[REMUX] FFmpeg stdout:\\n{e.stdout}\")\n",
        "        logging.error(f\"[REMUX] FFmpeg stderr:\\n{e.stderr}\")\n",
        "        # Update status file for remux failure (multi-line)\n",
        "        update_status_file(f\"Status: Remux Failed for {os.path.basename(input_path)}\\nError: {e.stderr.strip()}\")\n",
        "        # Clean up the incomplete remuxed file if it exists - HANDLED AFTER REMUX CALL\n",
        "        return False # Remux failed\n",
        "    except FileNotFoundError:\n",
        "        logging.error(\"[REMUX] FFmpeg command not found. Is FFmpeg installed and in PATH?\")\n",
        "        # Update status file for FFmpeg not found (multi-line)\n",
        "        update_status_file(f\"Status: Remux Failed\\nError: FFmpeg not found.\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logging.error(f\"[REMUX] An unexpected error occurred during remux: {e}\", exc_info=True)\n",
        "        # Update status file for unexpected remux error (multi-line)\n",
        "        update_status_file(f\"Status: Remux Failed for {os.path.basename(input_path)}\\nError: {e}\")\n",
        "        # Clean up the incomplete remuxed file if it exists - HANDLED AFTER REMUX CALL\n",
        "        return False\n",
        "\n",
        "# Reverted notify_completion to send to 'me' chat\n",
        "async def notify_completion(client, path, duration, remux_status='Skipped'):\n",
        "    \"\"\"Sends a completion message to the 'me' chat.\"\"\"\n",
        "    try:\n",
        "        # Ensure the file exists before trying to get its size\n",
        "        if not os.path.exists(path):\n",
        "            logging.warning(f\"[NOTIFY] File not found for completion notification: {os.path.basename(path)}\")\n",
        "            size_bytes = 0\n",
        "        else:\n",
        "            size_bytes = os.path.getsize(path)\n",
        "\n",
        "        size_mb = size_bytes / (1024 * 1024)\n",
        "        # Avoid division by zero if duration is 0 (very fast download)\n",
        "        avg_speed = size_mb / duration if duration > 0 else 0 # Corrected division by zero case\n",
        "\n",
        "        minutes = int(duration // 60)\n",
        "        seconds = int(duration % 60)\n",
        "\n",
        "        # Add remux status to the message\n",
        "        remux_line = f\"🔄 Remux: `{remux_status}`\"\n",
        "\n",
        "        msg = (\n",
        "            f\"✅ *Download complete*\\n\"\n",
        "            f\"📁 `{os.path.basename(path)}`\\n\"\n",
        "            f\"📦 Size: `{size_mb:.2f} MB`\\n\"\n",
        "            f\"⏱ Time: `{minutes}m {seconds}s`\\n\"\n",
        "            f\"🚀 Speed: `{avg_speed:.2f} MB/s`\\n\"\n",
        "            f\"{remux_line}\" # Include the remux status line\n",
        "        )\n",
        "        logging.info(f\"[NOTIFY] Attempting to send completion message for: {os.path.basename(path)}\")\n",
        "        # Use markdown parse_mode for formatting in Telegram message\n",
        "        # Corrected parse_mode to use enums.ParseMode.MARKDOWN\n",
        "        await client.send_message(\"me\", msg, parse_mode=enums.ParseMode.MARKDOWN)\n",
        "        logging.info(f\"[NOTIFY] Completion message sent successfully for: {os.path.basename(path)}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"[NOTIFY] Failed to send completion notification for {os.path.basename(path)}. Error: {e}\")\n",
        "\n",
        "def truncate_last_bytes(file_path, bytes_to_trim):\n",
        "    \"\"\"Truncates the end of a file. Useful for retrying partial downloads.\"\"\"\n",
        "    try:\n",
        "        size = os.path.getsize(file_path)\n",
        "        if size > bytes_to_trim:\n",
        "            # Open in read+write binary mode\n",
        "            with open(file_path, \"rb+\") as f:\n",
        "                # Seek to the position before the bytes to trim\n",
        "                f.seek(size - bytes_to_trim)\n",
        "                f.truncate() # Truncate the file at the current position\n",
        "            logging.info(f\"[TRUNCATE] Trimmed last {bytes_to_trim} bytes of: {file_path}\")\n",
        "        elif size > 0:\n",
        "             # If file is smaller than bytes_to_trim but not empty, truncate to 0\n",
        "             logging.warning(f\"[TRUNCATE] File size {size} is smaller than {bytes_to_trim}. Truncating to 0: {file_path}\")\n",
        "             with open(file_path, \"wb\") as f:\n",
        "                 pass # Open and close in write mode to clear content\n",
        "        else:\n",
        "            logging.info(f\"[TRUNCATE] File is empty or doesn't exist, no truncation needed: {file_path}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        logging.warning(f\"[TRUNCATE] File not found, cannot truncate: {file_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"[TRUNCATE] Failed to truncate {file_path}. Error: {e}\")\n",
        "\n",
        "# === Status File Management ===\n",
        "def update_status_file(status_message):\n",
        "    \"\"\"Writes the current status to the status file.\"\"\"\n",
        "    try:\n",
        "        # Ensure the directory for the status file exists\n",
        "        status_file_dir = os.path.dirname(DOWNLOADER_STATUS_FILE)\n",
        "        if status_file_dir and status_file_dir != '' and not os.path.exists(status_file_dir):\n",
        "            os.makedirs(status_file_dir, exist_ok=True)\n",
        "\n",
        "        with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f:\n",
        "            f.write(status_message)\n",
        "        # Changed this logging level from debug to info for cleaner combined log\n",
        "        # Log the status message on a single line for the combined log file\n",
        "        # Perform the replace outside the f-string expression\n",
        "        single_line_status = status_message.replace('\\n', ', ')\n",
        "        logging.info(f\"Status file updated: {single_line_status}\") # <--- Corrected line\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to write to status file {DOWNLOADER_STATUS_FILE}: {e}\")\n",
        "\n",
        "def clear_status_file():\n",
        "    \"\"\"Clears the content of the status file.\"\"\"\n",
        "    try:\n",
        "        # Ensure the directory for the status file exists\n",
        "        status_file_dir = os.path.dirname(DOWNLOADER_STATUS_FILE)\n",
        "        if status_file_dir and status_file_dir != '' and not os.path.exists(status_file_dir):\n",
        "            os.makedirs(status_file_dir, exist_ok=True)\n",
        "\n",
        "        with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"Downloader script started.\") # Write a default status\n",
        "        logging.info(\"Status file cleared.\") # Changed logging level to info\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to clear status file {DOWNLOADER_STATUS_FILE}: {e}\")\n",
        "\n",
        "# === Progress Bar Hook ===\n",
        "# This function is called periodically during download by client.stream_media\n",
        "# NOTE: This function might not be called by stream_media in some Pyrogram versions.\n",
        "# If progress updates stop, this is the likely reason.\n",
        "# Re-added time import for this function\n",
        "# def progress_hook(current, total, client, message, start_time):\n",
        "#     \"\"\"Updates the status file and potentially the Telegram message with download progress.\"\"\"\n",
        "#     # Update every 5% or on completion, and ensure enough time has passed or enough data downloaded\n",
        "#     # Added a time check (at least 1 second) and data check (at least 10KB) to avoid excessive updates\n",
        "#     current_time = time.time()\n",
        "#     # Check if it's time to update or if it's the very beginning (current == 0) or the very end (current == total)\n",
        "#     if current == 0 or current == total or \\\n",
        "#        (current_time - progress_hook.last_update_time > 1 or (current - progress_hook.last_update_bytes) > 10 * 1024):\n",
        "\n",
        "#         elapsed_time = current_time - start_time\n",
        "#         if elapsed_time > 0 and total > 0: # Avoid division by zero if total is 0\n",
        "#             speed = current / elapsed_time # bytes per second\n",
        "#             # Calculate ETA only if speed is reasonable and current is not 0\n",
        "#             if speed > 1024 and current > 0:\n",
        "#                  eta_seconds = (total - current) / speed\n",
        "#                  # Format ETA nicely (e.g., 1m 30s, 5h 10m)\n",
        "#                  if eta_seconds < 60:\n",
        "#                       eta_str = f\"{int(eta_seconds)}s\"\n",
        "#                  elif eta_seconds < 3600:\n",
        "#                       eta_str = f\"{int(eta_seconds // 60)}m {int((eta_seconds % 3600) // 60)}s\"\n",
        "#                  else:\n",
        "#                       eta_str = f\"{int(eta_seconds // 3600)}h {int((eta_seconds % 3600) // 60)}m\"\n",
        "#             else:\n",
        "#                  eta_str = \"Calculating...\"\n",
        "\n",
        "#             # Format speed nicely (e.g., 1.2 MB/s, 500 KB/s)\n",
        "#             if speed > 1024*1024:\n",
        "#                  speed_str = f\"{speed / (1024*1024):.2f}MB/s\"\n",
        "#             elif speed > 1024:\n",
        "#                  speed_str = f\"{speed / 1024:.2f}KB/s\"\n",
        "#             else:\n",
        "#                  speed_str = f\"{speed:.2f}B/s\"\n",
        "\n",
        "#             # Calculate overall progress percentage\n",
        "#             progress_percent = (current / total) * 100 if total > 0 else 0\n",
        "\n",
        "#             # Get filename from document or video media\n",
        "#             file_name = message.document.file_name if message.document else message.video.file_name if message.video else 'File'\n",
        "\n",
        "#             # Format the status message for the status file (multi-line for the file)\n",
        "#             status_message_file = (\n",
        "#                 f\"Downloading: {file_name}\\n\"\n",
        "#                 f\"Status: Downloading\\n\"\n",
        "#                 f\"Progress: {progress_percent:.1f}%\\n\"\n",
        "#                 f\"Speed: {speed_str}\\n\"\n",
        "#                 f\"ETA: {eta_str}\" # Include ETA in the status file\n",
        "#             )\n",
        "\n",
        "#             # Format the status message for the log (single line)\n",
        "#             status_message_log = (\n",
        "#                 f\"Downloading: {file_name}, \"\n",
        "#                 f\"Status: Downloading, \"\n",
        "#                 f\"Progress: {progress_percent:.1f}%, \"\n",
        "#                 f\"Speed: {speed_str}, \"\n",
        "#                 f\"ETA: {eta_str}\"\n",
        "#             )\n",
        "\n",
        "\n",
        "#             # Write the multi-line status to the status file\n",
        "#             try:\n",
        "#                 status_file_dir = os.path.dirname(DOWNLOADER_STATUS_FILE)\n",
        "#                 if status_file_dir and status_file_dir != '' and not os.path.exists(status_file_dir):\n",
        "#                     os.makedirs(status_file_dir, exist_ok=True)\n",
        "\n",
        "#                 with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f:\n",
        "#                     f.write(status_message_file)\n",
        "#             except Exception as e:\n",
        "#                 logging.error(f\"Failed to write to status file {DOWNLOADER_STATUS_FILE}: {e}\")\n",
        "\n",
        "#             # Log the single-line status using logging (goes to stderr now)\n",
        "#             # Corrected this line to use status_message_log instead of single_line_status\n",
        "#             logging.info(f\"Status file updated: {status_message_log}\")\n",
        "\n",
        "\n",
        "#             # Update last update time and bytes for debounce\n",
        "#             progress_hook.last_update_time = current_time\n",
        "#             progress_hook.last_update_bytes = current\n",
        "\n",
        "#         # Optional: Update the Telegram message itself with progress (can be noisy)\n",
        "#         # try:\n",
        "#         #     # Avoid editing too frequently to prevent FloodWait\n",
        "#         #     if int(current * 100 / total) % 10 == 0 or current == total:\n",
        "#         #         await message.edit_text(f\"Downloading: {current * 100 / total:.1f}%\")\n",
        "#         # except FloodWait as e:\n",
        "#         #     logging.warning(f\"FloodWait: Sleeping for {e.value} seconds.\")\n",
        "#         #     time.sleep(e.value)\n",
        "#         # except RPCError as e:\n",
        "#         #      logging.error(f\"RPC Error while editing message: {e}\")\n",
        "#         # except Exception as e:\n",
        "#         #      logging.error(f\"Error updating Telegram message: {e}\")\n",
        "\n",
        "# # Initialize debounce variables for the progress_hook function\n",
        "# progress_hook.last_update_time = 0\n",
        "# progress_hook.last_update_bytes = 0\n",
        "\n",
        "# Function to sanitize filenames\n",
        "def sanitize_filename(filename):\n",
        "    \"\"\"Sanitizes a string to be safe for use as a filename.\"\"\"\n",
        "    # Replace characters that are not alphanumeric, underscores, hyphens, spaces, or periods\n",
        "    # with underscores. Also, remove leading/trailing spaces and periods.\n",
        "    # This is a basic sanitization and might need adjustment based on specific filesystem requirements.\n",
        "    sanitized = re.sub(r'[^\\w\\s\\.\\-]', '_', filename).strip()\n",
        "    # Replace spaces with underscores for better compatibility\n",
        "    sanitized = re.sub(r'\\s+', '_', sanitized)\n",
        "    # Remove leading/trailing underscores and periods that might result from sanitization\n",
        "    sanitized = sanitized.strip('_.')\n",
        "    # Ensure the filename is not empty after sanitization\n",
        "    if not sanitized:\n",
        "        sanitized = \"sanitized_file\"\n",
        "    return sanitized\n",
        "\n",
        "\n",
        "async def download_media(client, message):\n",
        "    \"\"\"Main asynchronous function to handle downloading a single message's media.\"\"\"\n",
        "    logging.debug(f\"[DEBUG] Entering download_media function for message {message.id}.\")\n",
        "\n",
        "    media = message.document or message.video or message.audio or message.photo\n",
        "    if not media:\n",
        "        logging.warning(f\"Message {message.id} has no supported media.\")\n",
        "        logging.debug(f\"[DEBUG] Exiting download_media: No supported media.\")\n",
        "        return\n",
        "\n",
        "    logging.debug(f\"[DEBUG] Before determining filename.\")\n",
        "    # Determine filename and sanitize it\n",
        "    filename = getattr(media, 'file_name', None)\n",
        "    if not filename:\n",
        "        # Fallback filename if file_name is not available, sanitize the file_id\n",
        "        safe_id = ''.join(c for c in media.file_id if c.isalnum()) # Sanitize file_id\n",
        "        filename = f\"{safe_id}.bin\" # Use .bin as a generic fallback extension\n",
        "        logging.info(f\"[INFO] Generated and sanitized fallback filename {filename} for message {message.id}\")\n",
        "    else:\n",
        "         filename = sanitize_filename(filename) # Sanitize the provided filename\n",
        "         logging.info(f\"[INFO] Sanitized filename: {filename}\")\n",
        "\n",
        "\n",
        "    logging.debug(f\"[DEBUG] Before determining folder and path.\")\n",
        "    # Determine download folder based on media type\n",
        "    folder = DOWNLOAD_FOLDER if is_video(message) else OTHER_FOLDER\n",
        "    path = os.path.join(folder, filename)\n",
        "    total_size = media.file_size or 0 # Use 0 if file_size is None\n",
        "\n",
        "    logging.debug(f\"[DEBUG] Before os.makedirs.\")\n",
        "    # Ensure download folders exist (Corrected: Ensure DOWNLOAD_FOLDER exists)\n",
        "    os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)\n",
        "    os.makedirs(OTHER_FOLDER, exist_ok=True)\n",
        "    # Ensure remux temp directory exists\n",
        "    os.makedirs(REMUX_TEMP_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "    logging.debug(f\"[DEBUG] Before refined duplicate check.\")\n",
        "    # === Refined Duplicate Check ===\n",
        "    if os.path.exists(path):\n",
        "        current_file_size = os.path.getsize(path)\n",
        "        # Check if we have a stored pre-remux size for this filename (from the current run)\n",
        "        if filename in downloaded_file_sizes:\n",
        "            stored_pre_remux_size = downloaded_file_sizes[filename]\n",
        "            if current_file_size == stored_pre_remux_size and stored_pre_remux_size > 0:\n",
        "                logging.info(f\"[SKIP] Already complete (filename/stored size match): {filename}\")\n",
        "                # Update status file to show idle or last completed\n",
        "                try:\n",
        "                    with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f: # Added encoding\n",
        "                        f.write(f\"Idle (Last completed: {filename})\")\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Failed to write idle status to file: {e}\")\n",
        "                logging.debug(f\"[DEBUG] Exiting download_media: Duplicate (stored size match).\")\n",
        "                return\n",
        "            # If size doesn't match stored size, it's either a partial download or oversized relative to stored.\n",
        "            # Proceed to resume/redownload logic below.\n",
        "        # If no stored size (script restarted), check if current file size matches incoming message size.\n",
        "        # This handles remuxed files from previous runs that match the original size.\n",
        "        elif current_file_size == total_size and total_size > 0:\n",
        "            logging.info(f\"[SKIP] Already complete (filename/incoming size match from previous run): {filename}\")\n",
        "            # Store this size as the \"pre-remux\" size for future checks in this run\n",
        "            downloaded_file_sizes[filename] = total_size\n",
        "            # Update status file to show idle or last completed\n",
        "            try:\n",
        "                with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f: # Added encoding\n",
        "                    f.write(f\"Idle (Last completed: {filename})\")\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Failed to write idle status to file: {e}\")\n",
        "                logging.debug(f\"[DEBUG] Exiting download_media: Duplicate (incoming size match).\")\n",
        "                return\n",
        "        # If file exists but size doesn't match any complete condition,\n",
        "        # and it's not a zero-size file, it's either a partial download or oversized.\n",
        "        # The existing oversized check against incoming size is still relevant here if no stored size exists.\n",
        "        elif current_file_size > total_size and total_size > 0:\n",
        "            # This case is hit if file exists, no stored size, and current size > incoming size.\n",
        "            logging.warning(f\"[OVERSIZE] Existing file {path} is larger than expected (incoming size, no stored size). Redownloading.\")\n",
        "            try:\n",
        "                os.remove(path) # Remove and redownload\n",
        "                logging.info(f\"[OVERSIZE] Removed oversized file: {path}\")\n",
        "            except Exception as remove_e:\n",
        "                 logging.error(f\"[OVERSIZE] Failed to remove oversized file {path}: {remove_e}\")\n",
        "                 # If removal fails, we can't proceed safely, maybe log a critical error or skip?\n",
        "                 # For now, let's log and let the download attempt potentially fail again.\n",
        "                 pass # Continue to download attempt\n",
        "\n",
        "        # If file exists but size doesn't match any complete condition, proceed to resume logic.\n",
        "\n",
        "    logging.debug(f\"[DEBUG] After refined duplicate check. Before total_size == 0 check.\")\n",
        "    if total_size == 0:\n",
        "        logging.warning(f\"[ZERO_SIZE] Media reports zero size. Skipping download for {filename}.\")\n",
        "        # Update status file to show skipped\n",
        "        try:\n",
        "            with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f: # Added encoding\n",
        "                f.write(f\"Skipped (Zero size): {filename}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to write skipped status to file: {e}\")\n",
        "        logging.debug(f\"[DEBUG] Exiting download_media: Zero size media.\")\n",
        "        return\n",
        "    # === End Refined Duplicate Check ===\n",
        "\n",
        "    logging.debug(f\"[DEBUG] Before initializing retries and last_exception.\")\n",
        "    retries = 0\n",
        "    last_exception = None\n",
        "\n",
        "    # Removed progress_hook related debounce variables as progress_hook is removed\n",
        "\n",
        "    logging.debug(f\"[DEBUG] Before determining use_tqdm.\")\n",
        "    # Determine if tqdm should be enabled (only if total_size > 0 and stdout is a tty)\n",
        "    # TQDM prints to stderr by default, but we're logging to stdout, so check stdout\n",
        "    use_tqdm = total_size > 0 and sys.stdout.isatty()\n",
        "    logging.debug(f\"[DEBUG] TQDM enabled: {use_tqdm}\")\n",
        "\n",
        "    logging.debug(f\"[DEBUG] Entering retry loop for {filename}.\")\n",
        "\n",
        "    while retries < MAX_RETRIES:\n",
        "        logging.debug(f\"[DEBUG] Inside retry loop, before try block.\")\n",
        "        try:\n",
        "            logging.debug(f\"[DEBUG] Starting download attempt {retries + 1} for {filename}.\")\n",
        "            # Truncate before attempting resume download\n",
        "            if os.path.exists(path):\n",
        "                downloaded_so_far = os.path.getsize(path)\n",
        "                if downloaded_so_far > 0:\n",
        "                    logging.info(f\"[RESUME] Resuming download for {filename} from {downloaded_so_far} bytes.\")\n",
        "                    truncate_last_bytes(path, RETRY_TAIL_SIZE)\n",
        "                    logging.debug(f\"[DEBUG] After truncate_last_bytes for resume.\")\n",
        "\n",
        "\n",
        "            # Corrected: Use await client.download_media as it's an async function\n",
        "            start_time = time.time() # Use time.time()\n",
        "            logging.debug(f\"[DEBUG] Starting download using client.download_media for {filename}.\")\n",
        "            # Use the path variable directly as file_name argument\n",
        "            downloaded_path = await client.download_media(\n",
        "                message,\n",
        "                file_name=path,\n",
        "                # Removed progress and progress_args as download_media doesn't use them in this way\n",
        "            )\n",
        "            duration = time.time() - start_time # Calculate duration after download\n",
        "\n",
        "            logging.debug(f\"[DEBUG] client.download_media finished for {filename}. Returned path: {downloaded_path}\")\n",
        "\n",
        "            # Verify the downloaded_path is not None and exists\n",
        "            if not downloaded_path or not os.path.exists(downloaded_path):\n",
        "                 raise Exception(f\"Download failed or file not found after download_media for {filename}\")\n",
        "\n",
        "            # Final size check after download finishes\n",
        "            final_size = os.path.getsize(downloaded_path)\n",
        "            logging.debug(f\"[DEBUG] Final file size check. Expected: {total_size}, Got: {final_size}.\")\n",
        "            # Note: Telegram's reported size might not always exactly match the downloaded size,\n",
        "            # especially for some media types or due to container overhead.\n",
        "            # A strict equality check might be too brittle. Consider a small tolerance if needed.\n",
        "            # For now, keeping strict check as per previous logic.\n",
        "            if final_size != total_size:\n",
        "                 logging.warning(f\"[SIZE_MISMATCH] Downloaded file size mismatch for {filename}. Expected: {total_size}, Got: {final_size}\")\n",
        "                 # Depending on how critical exact size is, you might want to raise an error here\n",
        "                 # or just log the warning. Keeping as a warning for now.\n",
        "\n",
        "\n",
        "            # Store the size immediately after successful download (pre-remux)\n",
        "            downloaded_file_sizes[filename] = final_size\n",
        "            logging.info(f\"[SIZE_STORE] Stored pre-remux size for {filename}: {final_size} bytes\")\n",
        "            logging.debug(f\"[DEBUG] Size stored.\")\n",
        "\n",
        "            # --- Update Status File on Completion ---\n",
        "            completion_status_file = f\"Download Complete: {filename}\"\n",
        "            single_line_completion_status = completion_status_file.replace('\\n', ', ')\n",
        "            logging.info(f\"Status file updated: {single_line_completion_status}\")\n",
        "            try:\n",
        "                with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f_status:\n",
        "                    f_status.write(completion_status_file)\n",
        "                logging.debug(f\"[DEBUG] Completion status written to file.\")\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Failed to write completion status to file: {e}\")\n",
        "            # --- End Update Status File on Completion ---\n",
        "\n",
        "\n",
        "            # Perform video remuxing if applicable\n",
        "            remux_status = 'Skipped' # Initialize remux status\n",
        "            final_file_path = downloaded_path # Assume original downloaded file is the final one initially\n",
        "            logging.debug(f\"[DEBUG] Checking if remux is needed for {filename}.\")\n",
        "            if os.path.exists(downloaded_path) and is_video(message):\n",
        "                 logging.info(f\"[PROCESS] Original message was a video or document with video extension. Attempting remux of '{os.path.basename(downloaded_path)}'.\")\n",
        "                 remux_status = 'Attempted'\n",
        "                 logging.debug(f\"[DEBUG] Remux needed. Remux status set to 'Attempted'.\")\n",
        "\n",
        "                 # Define the temporary output path in the REMUX_TEMP_DIR\n",
        "                 # Use the original filename base with .mkv extension for the temporary file\n",
        "                 temp_remux_output_filename = os.path.splitext(filename)[0] + '.mkv'\n",
        "                 temp_remux_output_path = os.path.join(REMUX_TEMP_DIR, temp_remux_output_filename)\n",
        "                 logging.debug(f\"[DEBUG] Temporary remux output path: {temp_remux_output_path}\")\n",
        "\n",
        "                 # Call remux_video_ffmpeg to remux to the temporary directory\n",
        "                 logging.debug(f\"[DEBUG] Calling remux_video_ffmpeg.\")\n",
        "                 remux_success = remux_video_ffmpeg(downloaded_path, temp_remux_output_path)\n",
        "                 logging.debug(f\"[DEBUG] remux_video_ffmpeg returned: {remux_success}\")\n",
        "\n",
        "                 if remux_success:\n",
        "                     remux_status = 'Successful'\n",
        "                     logging.info(f\"[REMUX] Remux successful. Moving '{os.path.basename(temp_remux_output_path)}' to '{os.path.basename(downloaded_path)}' (replacing original).\")\n",
        "                     logging.debug(f\"[DEBUG] Remux successful. Attempting file move.\")\n",
        "\n",
        "                     # Move the successfully remuxed file from temp to the final download folder\n",
        "                     try:\n",
        "                         # Ensure the original downloaded file exists before attempting to remove it\n",
        "                         logging.debug(f\"[DEBUG] Checking if original downloaded file exists at {downloaded_path} before removal.\")\n",
        "                         if os.path.exists(downloaded_path):\n",
        "                             logging.debug(f\"[DEBUG] Original downloaded file exists. Removing {downloaded_path}.\")\n",
        "                             os.remove(downloaded_path)\n",
        "                             logging.info(f\"[REMUX] Removed original downloaded file '{os.path.basename(downloaded_path)}' after successful remux.\")\n",
        "                             logging.debug(f\"[DEBUG] Original downloaded file removed.\")\n",
        "                         else:\n",
        "                             logging.warning(f\"[REMUX] Original downloaded file not found at {downloaded_path} before removal attempt after remux.\")\n",
        "\n",
        "\n",
        "                         # Move the remuxed file to the original file's location\n",
        "                         logging.debug(f\"[DEBUG] Moving remuxed file from {temp_remux_output_path} to {downloaded_path}.\")\n",
        "                         shutil.move(temp_remux_output_path, downloaded_path)\n",
        "                         logging.info(f\"[REMUX] Successfully moved remuxed file to final location: '{os.path.basename(downloaded_path)}'.\")\n",
        "                         logging.debug(f\"[DEBUG] Remuxed file moved successfully.\")\n",
        "                         final_file_path = downloaded_path # The final file is now at the original download path\n",
        "\n",
        "                     except Exception as move_e:\n",
        "                         logging.error(f\"[REMUX] Failed to move remuxed file from temp to final location. Error: {move_e}\")\n",
        "                         remux_status = 'Move Failed'\n",
        "                         logging.debug(f\"[DEBUG] File move failed. Remux status set to 'Move Failed'.\")\n",
        "                         # Clean up the incomplete remuxed file in the temp directory if it exists\n",
        "                         logging.debug(f\"[DEBUG] Checking if incomplete remuxed file exists at {temp_remux_output_path} after move failure.\")\n",
        "                         if os.path.exists(temp_remux_output_path):\n",
        "                             logging.debug(f\"[DEBUG] Incomplete remuxed file exists. Attempting cleanup.\")\n",
        "                             try:\n",
        "                                 os.remove(temp_remux_output_path)\n",
        "                                 logging.info(f\"[REMUX] Cleaned up incomplete remuxed file in temp directory after move failure: {os.path.basename(temp_remux_output_path)}\")\n",
        "                                 logging.debug(f\"[DEBUG] Incomplete remuxed file cleaned up.\")\n",
        "                             except Exception as cleanup_e:\n",
        "                                 logging.error(f\"[REMUX] Failed to clean up incomplete remuxed file in temp directory after move failure: {cleanup_e}\")\n",
        "                                 logging.debug(f\"[DEBUG] Failed to clean up incomplete remuxed file.\")\n",
        "                         # The original file might still exist if the move failed before deletion, or it was deleted.\n",
        "                         # The final_file_path remains the original path, but the file might not be there.\n",
        "                         # The completion notification will check if the file exists.\n",
        "\n",
        "\n",
        "                 else:\n",
        "                     logging.error(f\"[REMUX] Remux failed for {os.path.basename(downloaded_path)}. Keeping original file.\")\n",
        "                     logging.debug(f\"[DEBUG] Remux failed. Keeping original file.\")\n",
        "                     # If remux failed, the status file is updated inside remux_video_ffmpeg\n",
        "                     # Clean up the incomplete remuxed file in the temp directory if it exists\n",
        "                     logging.debug(f\"[DEBUG] Checking if incomplete remuxed file exists at {temp_remux_output_path} after remux failure.\")\n",
        "                     if os.path.exists(temp_remux_output_path):\n",
        "                         logging.debug(f\"[DEBUG] Incomplete remuxed file exists. Attempting cleanup.\")\n",
        "                         try:\n",
        "                             os.remove(temp_remux_output_path)\n",
        "                             logging.info(f\"[REMUX] Cleaned up incomplete remuxed file in temp directory after remux failure: {os.path.basename(temp_remux_output_filename)}\") # Use filename for log clarity\n",
        "                             logging.debug(f\"[DEBUG] Incomplete remuxed file cleaned up.\")\n",
        "                         except Exception as cleanup_e:\n",
        "                             logging.error(f\"[REMUX] Failed to clean up incomplete remuxed file in temp directory after remux failure: {cleanup_e}\")\n",
        "                             logging.debug(f\"[DEBUG] Failed to clean up incomplete remuxed file.\")\n",
        "                     # final_file_path remains the original path, which should still exist\n",
        "            else:\n",
        "                logging.debug(f\"[DEBUG] Remux not needed or original file not found at {downloaded_path}.\")\n",
        "\n",
        "\n",
        "            logging.info(f\"[DEBUG] About to notify completion for {os.path.basename(final_file_path)}\")\n",
        "\n",
        "            # Notify completion, passing the remux status and the final file path\n",
        "            # duration is already calculated after download\n",
        "            logging.debug(f\"[DEBUG] Calling notify_completion with path: {final_file_path}, duration: {duration}, remux_status: {remux_status}.\")\n",
        "            await notify_completion(client, final_file_path, duration, remux_status)\n",
        "            logging.debug(f\"[DEBUG] notify_completion finished.\")\n",
        "\n",
        "\n",
        "            logging.debug(f\"[DEBUG] Download and processing successful for {filename}. Returning.\")\n",
        "            return # Exit the retry loop on success\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.debug(f\"[DEBUG] Exception caught in download_media try block: {e}\")\n",
        "            retries += 1\n",
        "            logging.warning(f\"[RETRY] Download/Processing for {filename} failed ({retries}/{MAX_RETRIES}): {e}\")\n",
        "            last_exception = e\n",
        "            logging.debug(f\"[DEBUG] Retries: {retries}, Last exception stored.\")\n",
        "\n",
        "\n",
        "            # --- Update Status File on Retry/Failure ---\n",
        "            retry_status_file = f\"Download Failed/Retrying: {filename} (Attempt {retries}/{MAX_RETRIES})\\nError: {e}\"\n",
        "            single_line_retry_status = retry_status_file.replace('\\n', ', ')\n",
        "            logging.info(f\"Status file updated: {single_line_retry_status}\")\n",
        "            try:\n",
        "                with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f_status:\n",
        "                    f_status.write(retry_status_file)\n",
        "                logging.debug(f\"[DEBUG] Retry/Failure status written to file.\")\n",
        "            except Exception as write_e:\n",
        "                logging.error(f\"Failed to write retry/failure status to file: {write_e}\")\n",
        "                logging.debug(f\"[DEBUG] Failed to write retry/failure status to file.\")\n",
        "            # --- End Update Status File on Retry/Failure ---\n",
        "\n",
        "\n",
        "            if retries < MAX_RETRIES:\n",
        "                logging.debug(f\"[DEBUG] Retries < MAX_RETRIES. Sleeping for {5 * retries} seconds.\")\n",
        "                await asyncio.sleep(5 * retries) # Exponential backoff\n",
        "                logging.debug(f\"[DEBUG] Finished sleeping. Continuing retry loop.\")\n",
        "            else:\n",
        "                # This block is reached only if all retries fail\n",
        "                logging.error(f\"[FAILED] Gave up on {filename} after {MAX_RETRIES} retries.\")\n",
        "                logging.debug(f\"[DEBUG] All retries failed. Attempting permanent failure notification.\")\n",
        "                # The status file is already updated with the last failure in the except block\n",
        "                # Reverted to sending failure notification to 'me' chat\n",
        "                try:\n",
        "                    failure_msg = (\n",
        "                        f\"❌ *Download Failed Permanently*\\n\"\n",
        "                        f\"File: `{filename}`\\n\"\n",
        "                        f\"Error: `{last_exception}`\" # Include the exception string\n",
        "                    )\n",
        "                    logging.debug(f\"[DEBUG] Sending permanent failure notification.\")\n",
        "                    await client.send_message(\"me\", failure_msg, parse_mode=enums.ParseMode.MARKDOWN)\n",
        "                    logging.debug(f\"[DEBUG] Permanent failure notification sent.\")\n",
        "                except Exception as notify_e:\n",
        "                    logging.error(f\"[NOTIFY] Failed to send permanent failure notification for {filename}. Error: {notify_e}\")\n",
        "                    logging.debug(f\"[DEBUG] Failed to send permanent failure notification.\")\n",
        "                finally:\n",
        "                    # Update status file to indicate permanent failure (multi-line for file, single for log)\n",
        "                    permanent_failure_status_file = f\"Download Failed Permanently: {filename}\\nError: {last_exception}\"\n",
        "                    single_line_permanent_failure_status = permanent_failure_status_file.replace('\\n', ', ')\n",
        "                    logging.error(f\"Status file updated: {single_line_permanent_failure_status}\")\n",
        "                    try:\n",
        "                        with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f_status:\n",
        "                            f_status.write(permanent_failure_status_file)\n",
        "                        logging.debug(f\"[DEBUG] Permanent failure status written to file.\")\n",
        "                    except Exception as write_e:\n",
        "                        logging.error(f\"Failed to write error shutdown status to file: {write_e}\")\n",
        "                        logging.debug(f\"[DEBUG] Failed to write permanent failure status to file.\")\n",
        "                logging.debug(f\"[DEBUG] Exiting retry loop after permanent failure.\")\n",
        "                return # Exit the retry loop after permanent failure\n",
        "\n",
        "\n",
        "# Removed Function to get CPU usage percentage\n",
        "# Removed Function to get memory usage details\n",
        "# Removed Function to get CPU temperature (specific to Raspberry Pi/Linux)\n",
        "\n",
        "# Removed Message Handler for Status Command\n",
        "\n",
        "\n",
        "# === Message Handler for other incoming messages (downloads) ===\n",
        "# This handler remains the same as before for processing media\n",
        "@app.on_message(filters.chat(chat_filter_id) & (filters.document | filters.video | filters.audio | filters.photo))\n",
        "async def handle_incoming(client, message):\n",
        "    logging.debug(f\"[DEBUG] Entering handle_incoming function for message {message.id}.\") # Added debug log\n",
        "    # Log the incoming message details\n",
        "    logging.info(f\"Received message {message.id} from chat {message.chat.id}. Downloading media...\")\n",
        "    # Removed the call to trigger_emby_scan_from_downloader here\n",
        "    logging.debug(f\"[DEBUG] Calling download_media for message {message.id}.\")\n",
        "    await download_media(client, message) # download_media is already awaited here\n",
        "    logging.debug(f\"[DEBUG] download_media finished for message {message.id}.\")\n",
        "\n",
        "\n",
        "# === Main execution block with KeyboardInterrupt handling ===\n",
        "logging.info(\"🟢 Bot running. Waiting for files...\")\n",
        "\n",
        "# Add a line to clear the status file when the script starts or stops cleanly\n",
        "try:\n",
        "    status_dir = os.path.dirname(DOWNLOADER_STATUS_FILE)\n",
        "    if status_dir and status_dir != '' and not os.path.exists(status_dir):\n",
        "        os.makedirs(status_dir, exist_ok=True)\n",
        "        logging.info(f\"Created status file directory: {status_dir}\")\n",
        "\n",
        "    with open(DOWNLOADER_STATUS_FILE, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"Downloader script started.\")\n",
        "    logging.info(f\"Initial status written to {DOWNLOADER_STATUS_FILE}\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to write initial status to file {DOWNLOADER_STATUS_FILE}: {e}\")\n",
        "\n",
        "\n",
        "# Corrected: Added the main function and asyncio.run(main()) call\n",
        "async def main():\n",
        "    \"\"\"Main function to run the Pyrogram client.\"\"\"\n",
        "    await app.start()\n",
        "    logging.info(\"Pyrogram client started.\")\n",
        "    # Keep the client running indefinitely until interrupted\n",
        "    await idle() # Use idle() to keep the client alive\n",
        "    await app.stop()\n",
        "    logging.info(\"Pyrogram client stopped.\")\n",
        "\n",
        "# Import idle from pyrogram.methods.utilities.idle\n",
        "from pyrogram.methods.utilities.idle import idle\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Added the missing closing parenthesis\n",
        "    asyncio.run(main())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "P_o9NarN8PtO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}